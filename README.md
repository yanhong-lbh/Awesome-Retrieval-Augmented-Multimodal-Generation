# Awesome-Retrieval-Augmented-Multimodal-Generation
A curated list of papers on Retrieval-Augmented Generation (RAG) applied to multimodal tasks (images, text, video, and beyond).

<!-- Table of Contents -->
- [Awesome-Retrieval-Augmented-Multimodal-Generation](#awesome-retrieval-augmented-multimodal-generation)
  - [Text - Image](#text---image)
  - [Text - Audio](#text---audio)
  - [Text - Video](#text---video)
  - [Dataset](#dataset)


## Text - Image

- **Retrieval-Augmented Multimodal Language Modeling**  
  *Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer, Wen-tau Yih*  
  [Paper](https://arxiv.org/abs/2211.12561) | ICML 2023 

- **MultiFusion: Fusing Pre-Trained Models for Multi-Lingual, Multi-Modal Image Generation**  
  *Marco Bellagente, Manuel Brack, Hannah Teufel, Felix Friedrich, Björn Deiseroth, Constantin Eichenberg, Andrew Dai, Robert Baldock, Souradeep Nanda, Koen Oostermeijer, Andres Felipe Cruz-Salinas, Patrick Schramowski, Kristian Kersting, Samuel Weinbach*  
  [Paper](https://arxiv.org/abs/2305.15296) | NeurIPS 2023

- **Generating Images with Multimodal Language Models**  
  *Jing Yu Koh, Daniel Fried, Ruslan Salakhutdinov*  
  [Paper](https://arxiv.org/abs/2305.17216) | NeurIPS 2023

- **EVCap: Retrieval-Augmented Image Captioning with External Visual-Name Memory for Open-World Comprehension**  
  *Jiaxuan Li, Duc Minh Vo, Akihiro Sugimoto, Hideki Nakayama*  
  [Paper](https://arxiv.org/abs/2311.15879) | CVPR 2024

- **Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models**  
  *Byung-Kwan Lee, Chae Won Kim, Beomchan Park, Yong Man Ro*  
  [Paper](https://arxiv.org/abs/2405.15574) | NeurIPS 2024

- **Unified Text-to-Image Generation and Retrieval**  
  *Leigang Qu, Haochuan Li, Tan Wang, Wenjie Wang, Yongqi Li, Liqiang Nie, Tat-Seng Chua*  
  [Paper](https://arxiv.org/abs/2406.05814) | ICLR 2024

- **ColPali: Efficient Document Retrieval with Vision Language Models**  
  *Manuel Faysse, Hugues Sibille, Tony Wu, Bilel Omrani, Gautier Viaud, Céline Hudelot, Pierre Colombo*  
  [Paper](https://arxiv.org/abs/2407.01449) | ICLR 2025

- **MM-Embed: Universal Multimodal Retrieval with Multimodal LLMs**  
  *Sheng-Chieh Lin, Chankyu Lee, Mohammad Shoeybi, Jimmy Lin, Bryan Catanzaro, Wei Ping*  
  [Paper](https://arxiv.org/abs/2411.02571) | ICLR 2025

- **Unified Generative and Discriminative Training for Multi-modal Large Language Models**  
  *Wei Chow, Juncheng Li, Qifan Yu, Kaihang Pan, Hao Fei, Zhiqi Ge, Shuai Yang, Siliang Tang, Hanwang Zhang, Qianru Sun*  
  [Paper](https://arxiv.org/abs/2411.00304) | NeurIPS 2024

- **VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents**  
  *Shi Yu, Chaoyue Tang, Bokai Xu, Junbo Cui, Junhao Ran, Yukun Yan, Zhenghao Liu, Shuo Wang, Xu Han, Zhiyuan Liu, Maosong Sun*  
  [Paper](https://arxiv.org/abs/2410.10594) | ICLR 2025

- **MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval**  
  *Junjie Zhou, Zheng Liu, Ze Liu, Shitao Xiao, Yueze Wang, Bo Zhao, Chen Jason Zhang, Defu Lian, Yongping Xiong*  
  [Paper](https://arxiv.org/abs/2412.14475)

- **UniCoRN: Unified Commented Retrieval Network with LMMs**  
  *Maximilian Jaritz, Matthieu Guillaumin, Sabine Sternig, Loris Bazzani*  
  [Paper](https://arxiv.org/abs/2502.08254)


## Text - Audio

- **Retrieval-Augmented Text-to-Audio Generation**  
  *Yi Yuan, Haohe Liu, Xubo Liu, Qiushi Huang, Mark D. Plumbley, Wenwu Wang*  
  [Paper](https://arxiv.org/abs/2309.08051) | ICASSP 2024

- **kNN-CTC: Enhancing ASR via Retrieval of CTC Pseudo Labels**
  *Jiaming Zhou, Shiwan Zhao, Yaqi Liu, Wenjia Zeng, Yong Chen, Yong Qin*
  [Paper](https://arxiv.org/abs/2312.13560v2) | ICASSP 2024

- **Retrieval Augmented End-to-End Spoken Dialog Models**  
  *Mingqiu Wang, Izhak Shafran, Hagen Soltau, Wei Han, Yuan Cao, Dian Yu, Laurent El Shafey*  
  [Paper](https://arxiv.org/abs/2402.01828) | ICASSP 2024

- **Multi-Modal Retrieval For Large Language Model Based Speech Recognition**
  *Aditya Gourav, Jari Kolehmainen, Prashanth Shivakumar, Yile Gu, Grant Strimel, Ankur Gandhe, Ariya Rastrow, Ivan Bulyko*  
  [Paper](https://arxiv.org/abs/2406.09618) | ACL 2024 Findings

- **Audiobox TTA-RAG: Improving Zero-Shot and Few-Shot Text-To-Audio with Retrieval-Augmented Generation**  
  *Mu Yang, Bowen Shi, Matthew Le, Wei-Ning Hsu, Andros Tjandra*  
  [Paper](https://arxiv.org/abs/2411.05141)


## Text - Video

- **Towards Efficient and Effective Text-to-Video Retrieval with Coarse-to-Fine Visual Representation Learning**  
  *Kaibin Tian, Yanhua Cheng, Yi Liu, Xinglin Hou, Quan Chen, Han Li*  
  [Paper](https://arxiv.org/abs/2401.00701) | AAAI 2024

- **Composed Video Retrieval via Enriched Context and Discriminative Embeddings**  
  *Omkar Thawakar, Muzammal Naseer, Rao Muhammad Anwer, Salman Khan, Michael Felsberg, Mubarak Shah, Fahad Shahbaz Khan*  
  [Paper](https://arxiv.org/abs/2403.16997) | CVPR 2024


## Dataset

- **UniIR: Training and Benchmarking Universal Multimodal Information Retrievers**  
  *Cong Wei, Yang Chen, Haonan Chen, Hexiang Hu, Ge Zhang, Jie Fu, Alan Ritter, Wenhu Chen*  
  [Paper](https://arxiv.org/abs/2311.17136) | ECCV 2024
